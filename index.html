<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Musicgen</title>
	
	<style>
		body{
			background-color:#85ca85;
			padding:2rem;
		}
		
		#downloading-model,
		#progress-bar{
			display:none;
		}
		#progress-bar{
			width:300px;
		}
		#progress-bar:before{
			content:'Generating audio...';
			display:block;
		}
		#prompt{
			width:300px;
			height:100px;
			padding:.5rem;
		}
		
		
	</style>
  </head>
  <body>
	  
	  <h1>üé∏ üé∫ ü•Å MusicGen.. running completely in the browser! üé∂ üéµ üé∂ </h1>
	  <p>This AI will generate a 10 second music clip tailored to your wishes. It's 100% privacy friendly, as the AI runs on your own computer, and not 'in the cloud'.</p>
	  <p>After the AI model is downloaded to your computer, which may take a few minutes, generating the audio can easily take another few minutes. In other words: please be patient.<p>
	  
	  <p>This is made possible by <a href="https://huggingface.co/docs/transformers.js/index" target="_blank">Transformers.js</a>.</p>
	  
	  <textarea id="prompt">80s pop track with bassy drums and synth</textarea><br/>
	  <button id="submit-button">MAKE THAT FUNKY MUSIC</button>
	  
	  <div id="downloading-model">Downloading AI model...</div>
	  <progress id="progress-bar" aria-label="Content loading‚Ä¶"></progress>
	  
	<script type="module">
		
		
		import { AutoTokenizer, MusicgenForConditionalGeneration } from './js/transformers.js';


		const downloading_model_el = document.getElementById('downloading-model');
		const progress_bar_el = document.getElementById('progress-bar');
		

		var logOfConsole = [];
		
		console.warn = function() {
		    logOfConsole.push({method: 'warn', arguments: arguments});
		    //return _warn.apply(console, arguments);
			console.log("logOfConsole.length (of 511): ", logOfConsole.length);
			progress_bar_el.value = (1/511) * logOfConsole.length;
			progress_bar_el.style.display = 'block';
			downloading_model_el.style.display = 'none';
		};


		function minFramesForTargetMS(targetDuration, frameSamples, sr = 16e3) {
		  return Math.ceil(targetDuration * sr / 1e3 / frameSamples);
		}
		function arrayBufferToBase64(buffer) {
		  var binary = "";
		  var bytes = new Uint8Array(buffer);
		  var len = bytes.byteLength;
		  for (var i = 0; i < len; i++) {
		    binary += String.fromCharCode(bytes[i]);
		  }
		  return btoa(binary);
		}


		function encodeWAV(samples, format = 3, sampleRate = 16e3, numChannels = 1, bitDepth = 32) {
		  var bytesPerSample = bitDepth / 8;
		  var blockAlign = numChannels * bytesPerSample;
		  var buffer = new ArrayBuffer(44 + samples.length * bytesPerSample);
		  var view = new DataView(buffer);
		  writeString(view, 0, "RIFF");
		  view.setUint32(4, 36 + samples.length * bytesPerSample, true);
		  writeString(view, 8, "WAVE");
		  writeString(view, 12, "fmt ");
		  view.setUint32(16, 16, true);
		  view.setUint16(20, format, true);
		  view.setUint16(22, numChannels, true);
		  view.setUint32(24, sampleRate, true);
		  view.setUint32(28, sampleRate * blockAlign, true);
		  view.setUint16(32, blockAlign, true);
		  view.setUint16(34, bitDepth, true);
		  writeString(view, 36, "data");
		  view.setUint32(40, samples.length * bytesPerSample, true);
		  if (format === 1) {
		    floatTo16BitPCM(view, 44, samples);
		  } else {
		    writeFloat32(view, 44, samples);
		  }
		  return buffer;
		}
		function writeFloat32(output, offset, input) {
		  for (var i = 0; i < input.length; i++, offset += 4) {
		    output.setFloat32(offset, input[i], true);
		  }
		}
		function floatTo16BitPCM(output, offset, input) {
		  for (var i = 0; i < input.length; i++, offset += 2) {
		    var s = Math.max(-1, Math.min(1, input[i]));
		    output.setInt16(offset, s < 0 ? s * 32768 : s * 32767, true);
		  }
		}

		function writeString(view, offset, string) {
		    for (let i = 0; i < string.length; ++i) {
		        view.setUint8(offset + i, string.charCodeAt(i))
		    }
		}
		
		
		
		const submit_button = document.getElementById('submit-button');
		submit_button.addEventListener('click', () => {
			console.log("making that funky music");
			make_funky_music();
		});
		
		async function make_funky_music(){
			
			submit_button.style.display = 'none';
			downloading_model_el.style.display = 'block';
			
			progress_bar_el.value = 0;
			
			// Load tokenizer and model
			const tokenizer = await AutoTokenizer.from_pretrained('Xenova/musicgen-small');
			const model = await MusicgenForConditionalGeneration.from_pretrained(
				//'Xenova/musicgen-small', { dtype: 'fp32' }
				'Xenova/musicgen-small', { dtype: 'q8' }
			);

			// Prepare text input
			const prompt = document.getElementById('prompt').value; //'80s pop track with bassy drums and synth';
			const inputs = tokenizer(prompt);

			// Generate audio
			const audio_values = await model.generate({
			  ...inputs,
			  max_new_tokens: 512,
			  do_sample: true,
			  guidance_scale: 3, // was 3
			});

			console.log("audio_values: ", audio_values);
			console.log("audio_values.ort_tensor: ", audio_values.ort_tensor);
			console.log("audio_values.ort_tensor.cpuData: ", audio_values.ort_tensor.cpuData);
		
			let wav = encodeWAV(audio_values.ort_tensor.cpuData,3,32000,1,32);
			let wav_blob = new Blob([wav], { type: 'audio/wav' });
			
			const audio_el = document.createElement('audio');
			audio_el.setAttribute('controls', true);
			audio_el.src = window.URL.createObjectURL(wav_blob);
			document.body.appendChild(audio_el);
			submit_button.style.display = 'block';
			progress_bar_el.style.display = 'none';
			
			
			
			// Stereo
			var channels = 1;

			// Create an empty two second stereo buffer at the
			// sample rate of the AudioContext
			var audioCtx = new (window.AudioContext || window.webkitAudioContext)();    
			var frameCount = audioCtx.sampleRate * 10.0;

			var myArrayBuffer = audioCtx.createBuffer(channels, frameCount, audioCtx.sampleRate);

		  for (var channel = 0; channel < channels; channel++) {
		    var nowBuffering = myArrayBuffer.getChannelData(channel);
		    for (var i = 0; i < frameCount; i++) {
				nowBuffering[i] = audio_values.ort_tensor.cpuData[i];
		    }
		  }

		  // Get an AudioBufferSourceNode.
		  // This is the AudioNode to use when we want to play an AudioBuffer
		  var source = audioCtx.createBufferSource();

		  // set the buffer in the AudioBufferSourceNode
		  source.buffer = myArrayBuffer;

		  // connect the AudioBufferSourceNode to the
		  // destination so we can hear the sound
		  source.connect(audioCtx.destination);

		  // start the source playing
		  source.start();
			
			
		}

		
		
		
	</script>
	
  </body>
</html>

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Musicgen</title>
	
	<style>
		
		
		:root{
		    font-family: Inter, system-ui, Avenir, Helvetica, Arial, sans-serif;
		    line-height: 1.5;
		    font-weight: 400;
		    color: #213547;
		    background-color: #fff;
		    font-synthesis: none;
		    text-rendering: optimizeLegibility;
		    -webkit-font-smoothing: antialiased;
		    -moz-osx-font-smoothing: grayscale;
		    -webkit-text-size-adjust: 100%;
		}
		
		*{
			box-sizing:border-box;
		}
		
		body{
			font-family: Inter, system-ui, Avenir, Helvetica, Arial, sans-serif;
			background-color: rgb(243 244 246);
			padding:2rem;
			display:flex;
			align-items:center;
			justify-content:center;
			height:100vh;
			width:100vw;
			
		}
		
		
		h1{
			color: rgb(31,41,55);
			font-weight: 600;
			text-align: center;
		}
		
		h2{
			font-weight:500;
		    font-size: 1rem;
		    line-height: 1.5rem;
			text-align: center;
		}
		
		label{
		    font-size: .875rem;
		    line-height: 1.25rem;
		}
		
		textarea{
			border: 1px solid rgb(209,213,219);
			width:100%;
			border-radius: .375rem;
			resize: vertical;
		    font-family: inherit;
		    font-feature-settings: inherit;
		    font-variation-settings: inherit;
		    font-size: 100%;
		    font-weight: inherit;
		    line-height: inherit;
		    color: inherit;
		}
		
		#guidance-scale{
			flex-grow:1;
		}
		
		
		#centered{
			max-width: 36rem;
			max-height:100vh;
			padding: 2rem;
			border-radius: .5rem;
			overflow:auto;
			background-color:white;
		    --tw-shadow: 0 10px 15px -3px rgb(0 0 0 / .1), 0 4px 6px -4px rgb(0 0 0 / .1);
		    --tw-shadow-colored: 0 10px 15px -3px var(--tw-shadow-color), 0 4px 6px -4px var(--tw-shadow-color);
		    box-shadow: var(--tw-ring-offset-shadow, 0 0 #0000), var(--tw-ring-shadow, 0 0 #0000), var(--tw-shadow);
		    
		}
		
		#downloading-model,
		#progress-bar{
			display:none;
		}
		#progress-bar{
			width:300px;
			padding:2rem 1rem;
		}
		#progress-bar:before{
			content:'Generating audio...';
			display:inline-block;
			position:relative;
			top:-.6rem;
		}
		#prompt{
			width:100%;
			height:100px;
			padding:.5rem;
			box-sizing:border-box;
		}
		
		.setting{
			justify-content:space-between;
			border-bottom:1px solid rgba(0, 0, 0, .1);
			margin:.8rem 0;
			padding:.3rem 0;
			width:300px;
		}
		.flex{
			display:flex;
		}
		.column{
			flex-direction:column;
		}
		
		
		button{
			padding:.5rem 1rem;
			border-radius:.375rem;
			cursor:pointer;
			border:none;
			background-color: rgb(59,130,246);
			color:white;
			font-size: 100%;
		}
		button:hover{
			background-color: rgb(37,99,235);
		}
		
		audio{
			margin-top:1rem;
		}
		
		.button-container{
			width:100%;
			padding:1rem;
			text-align: center;
		}
		
	</style>
  </head>
  <body>
	  
	<div id="centered">
		<h1>üé∏ üé∫ ü•Å MusicGen üé∂ üéµ üé∂ </h1>
    	<h2 class="text-base font-medium text-gray-700 mb-2 text-center">Made with <a href="https://huggingface.co/docs/transformers.js">ü§ó Transformers.js</a></h2>
      	<p>This AI will generate a 30 second music clip tailored to your wishes. It's 100% privacy friendly, as the AI runs completely on your own computer, and not 'in the cloud'.</p>
      	<p>After the AI model is downloaded to your computer, which may take a few minutes, generating the audio can easily take another few minutes. In other words: please be patient.<p>
		
      	<p>You can find this demo <a href="https://github.com/flatsiedatsie/transformers_js_musicgen">on Github</a>.</p>
	  	<br/>
    	<label for="prompt" class="block text-sm font-medium text-gray-600">Prompt</label><br/>
      	<textarea id="prompt">80s pop track with bassy drums and synth</textarea><br/>
	  
    	<div class="flex setting"><label>Max New Tokens</label>
        	<input id="new-tokens" type="number" value="512"/>
      	</div>
  	  	
    	<div class="flex setting"><label>Do Sample</label>
      	  	<input id="do-sample" type="checkbox" checked/>
        </div>
  	  	
	  
    	<div class="flex column setting">
    		<label>Guidance scale</label> 
    		<div class="flex">
    		    0 <input id="guidance-scale" type="range" min="0" max="20" step="1" value="3"/> 20
    	  	</div>
        </div>
		
		<br/>
    	
		<div class="button-container">
      	  	<button id="submit-button">Generate</button>
    	</div>
	  
    	<div id="downloading-model">Downloading AI model...</div>
    	<progress id="progress-bar" aria-label="Content loading‚Ä¶"></progress>
	  
    	<div id="output-container"></div>
    </div>
	  
	  
	  
	  
	<script type="module">
		
		import { AutoTokenizer, MusicgenForConditionalGeneration } from './js/transformers.js';


		const downloading_model_el = document.getElementById('downloading-model');
		const progress_bar_el = document.getElementById('progress-bar');
		const new_tokens_el = document.getElementById('new-tokens');
		const do_sample_el = document.getElementById('do-sample');
		const guidance_scale_el = document.getElementById('guidance-scale');
		const output_container_el = document.getElementById('output-container');

		
		
		// Hacky way of getting progress updates
		var logOfConsole = [];
		console.warn = function() {
		    logOfConsole.push({method: 'warn', arguments: arguments});
		    //return _warn.apply(console, arguments);
			console.log("logOfConsole.length (of 511): ", logOfConsole.length, arguments);
			progress_bar_el.value = (1/1510) * logOfConsole.length; // The 1510 hardcoded value is the maximum I've seen. Lowest was 511, It increases with the guidance scale value.
			progress_bar_el.style.display = 'block';
			downloading_model_el.style.display = 'none';
		};


		// Library for turning audio data array into a WAV file
		function minFramesForTargetMS(targetDuration, frameSamples, sr = 16e3) {
		  return Math.ceil(targetDuration * sr / 1e3 / frameSamples);
		}
		function arrayBufferToBase64(buffer) {
		  var binary = "";
		  var bytes = new Uint8Array(buffer);
		  var len = bytes.byteLength;
		  for (var i = 0; i < len; i++) {
		    binary += String.fromCharCode(bytes[i]);
		  }
		  return btoa(binary);
		}


		function encodeWAV(samples, format = 3, sampleRate = 16e3, numChannels = 1, bitDepth = 32) {
		  var bytesPerSample = bitDepth / 8;
		  var blockAlign = numChannels * bytesPerSample;
		  var buffer = new ArrayBuffer(44 + samples.length * bytesPerSample);
		  var view = new DataView(buffer);
		  writeString(view, 0, "RIFF");
		  view.setUint32(4, 36 + samples.length * bytesPerSample, true);
		  writeString(view, 8, "WAVE");
		  writeString(view, 12, "fmt ");
		  view.setUint32(16, 16, true);
		  view.setUint16(20, format, true);
		  view.setUint16(22, numChannels, true);
		  view.setUint32(24, sampleRate, true);
		  view.setUint32(28, sampleRate * blockAlign, true);
		  view.setUint16(32, blockAlign, true);
		  view.setUint16(34, bitDepth, true);
		  writeString(view, 36, "data");
		  view.setUint32(40, samples.length * bytesPerSample, true);
		  if (format === 1) {
		    floatTo16BitPCM(view, 44, samples);
		  } else {
		    writeFloat32(view, 44, samples);
		  }
		  return buffer;
		}
		function writeFloat32(output, offset, input) {
		  for (var i = 0; i < input.length; i++, offset += 4) {
		    output.setFloat32(offset, input[i], true);
		  }
		}
		function floatTo16BitPCM(output, offset, input) {
		  for (var i = 0; i < input.length; i++, offset += 2) {
		    var s = Math.max(-1, Math.min(1, input[i]));
		    output.setInt16(offset, s < 0 ? s * 32768 : s * 32767, true);
		  }
		}

		function writeString(view, offset, string) {
		    for (let i = 0; i < string.length; ++i) {
		        view.setUint8(offset + i, string.charCodeAt(i))
		    }
		}
		
		
		
		// Submit button
		const submit_button = document.getElementById('submit-button');
		submit_button.addEventListener('click', () => {
			console.log("making that funky music");
			make_funky_music();
		});
		
		
		
		// Main function that starts the (download and) music generation process
		async function make_funky_music(){
			
			submit_button.style.display = 'none';
			downloading_model_el.style.display = 'block';
			
			progress_bar_el.value = 0;
			logOfConsole = [];
			
			// Load tokenizer and model
			const tokenizer = await AutoTokenizer.from_pretrained('Xenova/musicgen-small');
			
			// The comments below are valid on 12 april 2024
			const model = await MusicgenForConditionalGeneration.from_pretrained('Xenova/musicgen-small', {
			    dtype: {
			        text_encoder: 'q8', // or 'fp32'. Both seem to work well, but q8 provides 4x memory reduction.
			        decoder_model_merged: 'q8', // IMPORTANT: otherwise, you'll get out-of-memory issues
			        encodec_decode: 'fp32', // IMPORTANT: If not full-precision, quality won't be very good.
			    },
			    device: {
			        text_encoder: 'webgpu', // much faster :)
			        decoder_model_merged: 'wasm', // webgpu is slower at the moment due to inefficient buffer reuse. Will fix.
			        encodec_decode: 'wasm', // webgpu is currently broken (known upstream bug in onnxruntime-web). Will be fixed soon.
			    },
			});
			

			// Prepare text input
			const prompt = document.getElementById('prompt').value; //'80s pop track with bassy drums and synth';
			const inputs = tokenizer(prompt);

			let guidance_scale = guidance_scale_el.value;
			if(guidance_scale == 0){guidance_scale = null}

			console.log("max new token: ", new_tokens_el.value);
			console.log("do_sample: ", do_sample_el.checked);
			console.log("guidance_scale: ", guidance_scale);

			// Generate audio
			const audio_values = await model.generate({
			  ...inputs,
			  max_new_tokens: new_tokens_el.value,
			  do_sample: do_sample_el.checked,
			  guidance_scale: guidance_scale, // default is 3. Null disables it. Greatly increases memory usage.
			});

			console.log("audio_values: ", audio_values);
			console.log("audio_values.ort_tensor: ", audio_values.ort_tensor);
			console.log("audio_values.ort_tensor.cpuData: ", audio_values.ort_tensor.cpuData);
		
			let wav = encodeWAV(audio_values.ort_tensor.cpuData, 3, 32000, 1, 32); // The MusicGen model outputs at a samplerate of 32000, 1 channel (mono), 32 bit data,
			let wav_blob = new Blob([wav], { type: 'audio/wav' });
			
			const audio_el = document.createElement('audio');
			audio_el.setAttribute('controls', true);
			audio_el.src = window.URL.createObjectURL(wav_blob);
			output_container_el.appendChild(audio_el);
			submit_button.style.display = 'block';
			progress_bar_el.style.display = 'none';
			
			
			/*
			
			// The code below instantly plays the music after it has been created
			// Stereo
			var channels = 1;

			// Create an empty two second stereo buffer at the
			// sample rate of the AudioContext
			var audioCtx = new (window.AudioContext || window.webkitAudioContext)();    
			var frameCount = audioCtx.sampleRate * 10.0;

			var myArrayBuffer = audioCtx.createBuffer(channels, frameCount, audioCtx.sampleRate);

		  for (var channel = 0; channel < channels; channel++) {
		    var nowBuffering = myArrayBuffer.getChannelData(channel);
		    for (var i = 0; i < frameCount; i++) {
				nowBuffering[i] = audio_values.ort_tensor.cpuData[i];
		    }
		  }

		  // Get an AudioBufferSourceNode.
		  // This is the AudioNode to use when we want to play an AudioBuffer
		  var source = audioCtx.createBufferSource();

		  // set the buffer in the AudioBufferSourceNode
		  source.buffer = myArrayBuffer;

		  // connect the AudioBufferSourceNode to the
		  // destination so we can hear the sound
		  source.connect(audioCtx.destination);

		  // start the source playing
		  source.start();
			*/
			
			
		} // end of make_funky_music()

		
		
		
	</script>
	
  </body>
</html>
